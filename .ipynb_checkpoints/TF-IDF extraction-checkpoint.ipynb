{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use sklearn to extract tf-idf\n",
    "- CountVectorizer() + TfidfTransformer()\n",
    "- TfidfVectorizer()\n",
    "\"As tf–idf is very often used for text features, there is also another class called TfidfVectorizer that combines all the options of CountVectorizer and TfidfTransformer in a single model.\n",
    "As you can see, TfidfVectorizer is a CountVectorizer followed by TfidfTransformer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='all')\n",
    "news_data = twenty_train.data[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(news_data)\n",
    "# show the matrix of the vectorized corpus\n",
    "X.toarray()\n",
    "# show the unique terms (feature names)\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count tf-idf of each term in the vectorized corpus\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(X)\n",
    "tfidfArray = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'pens', 0.57457982949654918), (u'devils', 0.19152660983218306), (u'jagr', 0.19152660983218306), (u'season', 0.15663692903159965), (u'regular', 0.15663692903159965)]\n",
      "[(u'vlb', 0.31282633392421016), (u'uoknor', 0.28687950970352283), (u'ecn', 0.28687950970352283), (u'card', 0.20992053310059022), (u'performance', 0.20072488892546592)]\n",
      "[(u'hilmi', 0.21799238139149693), (u'armenians', 0.21799238139149693), (u'weapons', 0.21393783685745585), (u'armenia', 0.21393783685745585), (u'announced', 0.17828153071454655)]\n",
      "[(u'scsi', 0.35871726913937901), (u'dma', 0.35871726913937901), (u'bus', 0.30854605792918893), (u'data', 0.27608745039290811), (u'devices', 0.25110208839756537)]\n",
      "[(u'system', 0.29716049705138053), (u'drive', 0.25381328734924902), (u'jasmine', 0.2418362493420185), (u'inexpensive', 0.2418362493420185), (u'utility', 0.2418362493420185)]\n",
      "[(u'myers', 0.31264602206683523), (u'unc', 0.31264602206683523), (u'fc', 0.23448451655012642), (u'tell', 0.21875329512801253), (u'chapel', 0.15632301103341761)]\n",
      "[(u'214', 0.33693573913203234), (u'tamuts', 0.33693573913203234), (u'tamu', 0.27555742517907528), (u'241', 0.27555742517907528), (u'number', 0.27555742517907528)]\n",
      "[(u'hockey', 0.32928744603714666), (u'ists', 0.26930239281690804), (u'abc', 0.24696558452785997), (u'00', 0.20197679461268106), (u'stpl', 0.20197679461268106)]\n",
      "[(u'buffalo', 0.32071164372342265), (u'price', 0.26228881209524846), (u'ists', 0.26228881209524846), (u'fuhr', 0.21380776248228178), (u'acsu', 0.21380776248228178)]\n",
      "[(u'arromdee', 0.39489625080597607), (u'jesus', 0.29617218810448209), (u'turkey', 0.27630243150523315), (u'truelove', 0.19744812540298803), (u'day', 0.19744812540298803)]\n",
      "[(u'sandvik', 0.28374180160141615), (u'blood', 0.28374180160141615), (u'lamb', 0.23129541530372166), (u'newton', 0.23129541530372166), (u'bull', 0.23129541530372166)]\n",
      "[(u'access', 0.27630383062282748), (u'digex', 0.25971872702602933), (u'steve', 0.25971872702602933), (u'fighting', 0.18559726566274753), (u'generally', 0.18559726566274753)]\n",
      "[(u'reuss', 0.41655167572691287), (u'order', 0.37535308479109991), (u'crowley', 0.16662067029076513), (u'frater', 0.13885055857563761), (u'the', 0.13214589741379407)]\n",
      "[(u'cern', 0.34768771701234508), (u'fr', 0.23179181134156338), (u'unlv', 0.23179181134156338), (u'filipe', 0.23179181134156338), (u'european', 0.23179181134156338)]\n",
      "[(u'notion', 0.36121175556906321), (u'monash', 0.24080783704604217), (u'geocentrism', 0.24080783704604217), (u'verse', 0.24080783704604217), (u'cwru', 0.24080783704604217)]\n",
      "[(u'turanist', 0.32261085996404937), (u'adriatic', 0.24195814497303703), (u'china', 0.24195814497303703), (u'turkey', 0.22572552880948282), (u'regional', 0.19788154145247483)]\n",
      "[(u'warwick', 0.43792746879598937), (u'ac', 0.2865214976065808), (u'uk', 0.2690554965476355), (u'csv', 0.26275648127759366), (u'drive', 0.18384640148540934)]\n",
      "[(u'adelphi', 0.27650055830952303), (u'schmidt', 0.20737541873214227), (u'cover', 0.20737541873214227), (u'wd', 0.20737541873214227), (u'auvax1', 0.20737541873214227)]\n",
      "[(u'constitution', 0.2957910936367959), (u'amendment', 0.25881720693219645), (u'people', 0.1846729820805611), (u'arms', 0.18109015581891347), (u'the', 0.17362762911503152)]\n",
      "[(u'brake', 0.20037231707986794), (u'official', 0.20037231707986794), (u'riding', 0.20037231707986794), (u'uea', 0.20037231707986794), (u'countersteering', 0.20037231707986794)]\n",
      "[(u'chevrolet', 0.30070998113509922), (u'grady', 0.2405679849080794), (u'truck', 0.18042598868105955), (u'cab', 0.18042598868105955), (u'hd', 0.18042598868105955)]\n",
      "[(u'faultline', 0.34791003524817393), (u'app', 0.27832802819853913), (u'title', 0.27832802819853913), (u'hoswell', 0.27832802819853913), (u'application', 0.20874602114890439)]\n",
      "[(u'amiga', 0.4636098220431415), (u'3d', 0.31596313978404389), (u'ruocco', 0.30907321469542764), (u'sergio', 0.23180491102157075), (u'imagine', 0.21625346039419341)]\n",
      "[(u'behind', 0.30677243157063971), (u'car', 0.23045756661986194), (u'screeching', 0.22506219001591962), (u'hydro', 0.22506219001591962), (u'jody', 0.22506219001591962)]\n",
      "[(u'draft', 0.33417631685871885), (u'kariya', 0.26734105348697512), (u'picks', 0.26734105348697512), (u'maine', 0.26734105348697512), (u'go', 0.16424998434390239)]\n",
      "[(u'lunar', 0.30503803152013764), (u'crystal', 0.30503803152013764), (u'exploration', 0.30503803152013764), (u'manned', 0.30503803152013764), (u'city', 0.24947040276556881)]\n",
      "[(u'almanac', 0.26090523881616196), (u'proof', 0.21337711460683198), (u'frog', 0.19567892911212148), (u'hear', 0.13691333811772188), (u'broadcast', 0.13045261940808098)]\n",
      "[(u'vmode', 0.39819485671417298), (u'vesa', 0.27861041197137371), (u'geoffrey_hansen', 0.26546323780944869), (u'mindlink', 0.26546323780944869), (u'speedstar', 0.26546323780944869)]\n",
      "[(u'weitek', 0.33088876718089394), (u'processor', 0.19853326030853641), (u'autocad', 0.19853326030853641), (u'local', 0.18521395580383956), (u'bus', 0.16263413080829464)]\n",
      "[(u'moral', 0.2763232549740634), (u'position', 0.19306980095460902), (u'wrong', 0.17792840663893705), (u'ask', 0.15893599383200741), (u'sni', 0.14480235071595676)]\n",
      "[(u'johnson', 0.30869167504891964), (u'comparing', 0.28308779275931556), (u'crash', 0.28308779275931556), (u'spectra', 0.18872519517287703), (u'consumer', 0.18872519517287703)]\n",
      "[(u'feustel', 0.54564563868017457), (u'netcom', 0.27282281934008729), (u'die', 0.22312371439466358), (u'federal', 0.19088965316820955), (u'national', 0.13641140967004364)]\n",
      "[(u'steer', 0.3578201643804505), (u'server', 0.29263741337689558), (u'nt', 0.29263741337689558), (u'westinghouse', 0.17891008219022525), (u'h01', 0.17891008219022525)]\n",
      "[(u'lankford', 0.34471524047831564), (u'he', 0.30634264180537851), (u'wuvmd', 0.2298101603188771), (u'du', 0.2298101603188771), (u'kornbluh', 0.2298101603188771)]\n",
      "[(u'inject', 0.37414216958181379), (u'radford', 0.37414216958181379), (u'assistance', 0.18707108479090689), (u'injections', 0.18707108479090689), (u'onset', 0.18707108479090689)]\n",
      "[(u'iisi', 0.47899750033328048), (u'missouri', 0.35924812524996036), (u'ls', 0.35924812524996036), (u'pb', 0.29380524799566377), (u'mizzou1', 0.23949875016664024)]\n",
      "[(u'desi', 0.35102399664752743), (u'hades', 0.35102399664752743), (u'dartmouth', 0.28707927791048982), (u'eclipse', 0.23401599776501827), (u'perform', 0.23401599776501827)]\n",
      "[(u'health', 0.31952323139058825), (u'inefficient', 0.29302094491324138), (u'cross', 0.29302094491324138), (u'blue', 0.23964242354294124), (u'vastly', 0.1953472966088276)]\n",
      "[(u'bnr', 0.38445055567288627), (u'nick', 0.25630037044859089), (u'karr', 0.19222527783644314), (u'npet', 0.19222527783644314), (u'01', 0.19222527783644314)]\n",
      "[(u'lsid', 0.36887602145518117), (u'2253', 0.18443801072759058), (u'damage', 0.18443801072759058), (u'kens', 0.18443801072759058), (u'chain', 0.18443801072759058)]\n",
      "[(u'probe', 0.26672809982319229), (u'event', 0.26672809982319229), (u'horizon', 0.26672809982319229), (u'black', 0.2181392469659765), (u'keith', 0.18662527785843258)]\n",
      "[(u'jhunix', 0.26917934621129863), (u'unions', 0.26917934621129863), (u'naiman', 0.26917934621129863), (u'hcf', 0.26917934621129863), (u'jhu', 0.22014395903637335)]\n",
      "[(u'acetone', 0.33753009224676078), (u'mek', 0.28127507687230063), (u'neilson', 0.22502006149784051), (u'ethyl', 0.22502006149784051), (u'methyl', 0.22502006149784051)]\n",
      "[(u'welty', 0.46598704756825354), (u'archive', 0.37278963805460291), (u'autos', 0.27959222854095211), (u'cma', 0.27959222854095211), (u'cabot', 0.27959222854095211)]\n",
      "[(u'det', 0.36597023170303505), (u'nyr', 0.32530687262491997), (u'tor', 0.31717420080929709), (u'mtl', 0.26837816991555902), (u'chi', 0.24398015446869004)]\n",
      "[(u'eisa', 0.38921559059287625), (u'xfree86', 0.311372472474301), (u'larry', 0.25465092248061794), (u'gator', 0.23352935435572575), (u'rn', 0.23352935435572575)]\n",
      "[(u'arizona', 0.38928072901028754), (u'gibson', 0.25952048600685834), (u'gibsonm', 0.25952048600685834), (u'comm', 0.25952048600685834), (u'matthew', 0.21224461699875941)]\n",
      "[(u'counterpoint', 0.31157059369727941), (u'tube', 0.31157059369727941), (u'unh', 0.31157059369727941), (u'kepler', 0.31157059369727941), (u'sa', 0.31157059369727941)]\n",
      "[(u'qualcomm', 0.45214644334468179), (u'cylink', 0.25836939619696098), (u'servalan', 0.19377704714772073), (u'phones', 0.19377704714772073), (u'someone', 0.14179395761637498)]\n",
      "[(u'philips', 0.46269774551316423), (u'address', 0.30272787260435613), (u'dewinter', 0.27761864730789859), (u'prl', 0.27761864730789859), (u'nl', 0.27761864730789859)]\n"
     ]
    }
   ],
   "source": [
    "# view teh top 5 terms of each news article based on the tfidf score\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "li = []\n",
    "for l in tfidfArray:\n",
    "    # How to explain this : ???\n",
    "    print [(feature_names[x],l[x]) for x in (l*-1).argsort()][:5]\n",
    "    \n",
    "# reference: https://stackoverflow.com/questions/28619595/how-to-get-top-terms-based-on-tf-idf-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------Writing all the tf-idf in the 0  file into  ./tfidffile/00000.txt --------\n",
      "--------Writing all the tf-idf in the 1  file into  ./tfidffile/00001.txt --------\n",
      "--------Writing all the tf-idf in the 2  file into  ./tfidffile/00002.txt --------\n",
      "--------Writing all the tf-idf in the 3  file into  ./tfidffile/00003.txt --------\n",
      "--------Writing all the tf-idf in the 4  file into  ./tfidffile/00004.txt --------\n",
      "--------Writing all the tf-idf in the 5  file into  ./tfidffile/00005.txt --------\n",
      "--------Writing all the tf-idf in the 6  file into  ./tfidffile/00006.txt --------\n",
      "--------Writing all the tf-idf in the 7  file into  ./tfidffile/00007.txt --------\n",
      "--------Writing all the tf-idf in the 8  file into  ./tfidffile/00008.txt --------\n",
      "--------Writing all the tf-idf in the 9  file into  ./tfidffile/00009.txt --------\n",
      "--------Writing all the tf-idf in the 10  file into  ./tfidffile/00010.txt --------\n",
      "--------Writing all the tf-idf in the 11  file into  ./tfidffile/00011.txt --------\n",
      "--------Writing all the tf-idf in the 12  file into  ./tfidffile/00012.txt --------\n",
      "--------Writing all the tf-idf in the 13  file into  ./tfidffile/00013.txt --------\n",
      "--------Writing all the tf-idf in the 14  file into  ./tfidffile/00014.txt --------\n",
      "--------Writing all the tf-idf in the 15  file into  ./tfidffile/00015.txt --------\n",
      "--------Writing all the tf-idf in the 16  file into  ./tfidffile/00016.txt --------\n",
      "--------Writing all the tf-idf in the 17  file into  ./tfidffile/00017.txt --------\n",
      "--------Writing all the tf-idf in the 18  file into  ./tfidffile/00018.txt --------\n",
      "--------Writing all the tf-idf in the 19  file into  ./tfidffile/00019.txt --------\n",
      "--------Writing all the tf-idf in the 20  file into  ./tfidffile/00020.txt --------\n",
      "--------Writing all the tf-idf in the 21  file into  ./tfidffile/00021.txt --------\n",
      "--------Writing all the tf-idf in the 22  file into  ./tfidffile/00022.txt --------\n",
      "--------Writing all the tf-idf in the 23  file into  ./tfidffile/00023.txt --------\n",
      "--------Writing all the tf-idf in the 24  file into  ./tfidffile/00024.txt --------\n",
      "--------Writing all the tf-idf in the 25  file into  ./tfidffile/00025.txt --------\n",
      "--------Writing all the tf-idf in the 26  file into  ./tfidffile/00026.txt --------\n",
      "--------Writing all the tf-idf in the 27  file into  ./tfidffile/00027.txt --------\n",
      "--------Writing all the tf-idf in the 28  file into  ./tfidffile/00028.txt --------\n",
      "--------Writing all the tf-idf in the 29  file into  ./tfidffile/00029.txt --------\n",
      "--------Writing all the tf-idf in the 30  file into  ./tfidffile/00030.txt --------\n",
      "--------Writing all the tf-idf in the 31  file into  ./tfidffile/00031.txt --------\n",
      "--------Writing all the tf-idf in the 32  file into  ./tfidffile/00032.txt --------\n",
      "--------Writing all the tf-idf in the 33  file into  ./tfidffile/00033.txt --------\n",
      "--------Writing all the tf-idf in the 34  file into  ./tfidffile/00034.txt --------\n",
      "--------Writing all the tf-idf in the 35  file into  ./tfidffile/00035.txt --------\n",
      "--------Writing all the tf-idf in the 36  file into  ./tfidffile/00036.txt --------\n",
      "--------Writing all the tf-idf in the 37  file into  ./tfidffile/00037.txt --------\n",
      "--------Writing all the tf-idf in the 38  file into  ./tfidffile/00038.txt --------\n",
      "--------Writing all the tf-idf in the 39  file into  ./tfidffile/00039.txt --------\n",
      "--------Writing all the tf-idf in the 40  file into  ./tfidffile/00040.txt --------\n",
      "--------Writing all the tf-idf in the 41  file into  ./tfidffile/00041.txt --------\n",
      "--------Writing all the tf-idf in the 42  file into  ./tfidffile/00042.txt --------\n",
      "--------Writing all the tf-idf in the 43  file into  ./tfidffile/00043.txt --------\n",
      "--------Writing all the tf-idf in the 44  file into  ./tfidffile/00044.txt --------\n",
      "--------Writing all the tf-idf in the 45  file into  ./tfidffile/00045.txt --------\n",
      "--------Writing all the tf-idf in the 46  file into  ./tfidffile/00046.txt --------\n",
      "--------Writing all the tf-idf in the 47  file into  ./tfidffile/00047.txt --------\n",
      "--------Writing all the tf-idf in the 48  file into  ./tfidffile/00048.txt --------\n",
      "--------Writing all the tf-idf in the 49  file into  ./tfidffile/00049.txt --------\n"
     ]
    }
   ],
   "source": [
    "# store tf-idf in the file\n",
    "import os\n",
    "import string\n",
    "\n",
    "word = vectorizer.get_feature_names()\n",
    "weight = tfidf.toarray()\n",
    "\n",
    "sFilePath = './tfidffile'\n",
    "if not os.path.exists(sFilePath) : \n",
    "    os.mkdir(sFilePath)\n",
    "# 这里将每份文档词语的TF-IDF写入tfidffile文件夹中保存\n",
    "for i in range(len(weight)) :\n",
    "    print u\"--------Writing all the tf-idf in the\",i,u\" file into \",sFilePath+'/'+string.zfill(i,5)+'.txt',\"--------\"\n",
    "    f = open(sFilePath+'/'+string.zfill(i,5)+'.txt','w+')\n",
    "    for j in range(len(word)) :\n",
    "        f.write(word[j]+\"    \"+str(weight[i][j])+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: http://blog.csdn.net/liuxuejiang158blog/article/details/31360765"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
